\section{Introduction}
\IEEEPARstart{T}{here} are many tasks in AI that require both low-level perception and high-level reasoning but the integration of the two is an open challenge in the field of artificial intelligence. Today, low-level perception is typically achieved by deep neural networks, while high-level reasoning is typically handled using logical and probabilistic representations and inference. Even if deep learning can create intelligent systems used to interpret images, text and speech with unprecedented accuracy, there is a growing awareness of its limitations: deep learning requires large amounts of data to train a network and the models are black-boxes that do not provide explanations and cannot be modified by domain experts. 

The abilities of deep learning and probabilistic logic approaches are complementary: deep learning excels at low-level perception and probabilistic logic excels at high-level reasoning. Recently, there has been a lot of progress in both deep learning and high-level reasoning areas and today there exists approaches able to integrate logical and probabilistic reasoning with statistical learning.
% TODO: in order to exploit strenghts and weakenesses of both

DeepProbLog \cite{DeepProbLog} is one possible approach. It is a neural probabilistic logic programming language that incorporates deep learning by means of neural predicates. With DeepProbLog, instead of integrating reasoning capabilities into a complex neural network architecture, the authors have decided to start from an existing probabilistic logic programming language, ProbLog \cite{ProbLog}, that has been extended with the neural predicates. In this way, the framework exploits the full expressiveness and strengths of general-purpose neural networks and expressive probabilistic-logical modeling and reasoning and can be trained end-to-end based on examples.

% In the next sections, 
In this work, we introduce DeepProbLog explainig the basics of the language in Section \ref{sec:DeepProbLog}. Subsequently, in Section \ref{sec:task} we present the multi-digit MNIST octal-division task and how can be solved using DeepProbLog. Finally, in Section \ref{TODO} and \ref{TODO} we discuss the results obtained.

% TODO: finish introduction