\section{Introduction}
% \IEEEPARstart{T}{here} are many tasks in AI that require both low-level perception and high-level reasoning but the integration of the two is an open challenge in the field of artificial intelligence.
\IEEEPARstart{A}{rtificial} intelligence tasks often require both low-level perception and high-level reasoning, but integrating the two remains an open challenge in the field.
Today, low-level perception is typically achieved by deep neural networks, while high-level reasoning is typically handled using logical and probabilistic representations and inference. Even if deep learning can create intelligent systems used to interpret images, text and speech with unprecedented accuracy, there is a growing awareness of its limitations: deep learning requires large amounts of data to train a network and the models are black-boxes that do not provide explanations and cannot be modified by domain experts. 

The abilities of deep learning and probabilistic logic approaches are complementary: deep learning excels at low-level perception and probabilistic logic excels at high-level reasoning. Recently, there has been a lot of progress in both deep learning and high-level reasoning areas and today there exists approaches able to integrate logical and probabilistic reasoning with statistical learning.
% TODO: in order to exploit strenghts and weakenesses of both

DeepProbLog \cite{DeepProbLog} is one possible approach. It is a neural probabilistic logic programming language that incorporates deep learning by means of neural predicates. With DeepProbLog, instead of integrating reasoning capabilities into a complex neural network architecture, the authors have decided to start from an existing probabilistic logic programming language, ProbLog \cite{ProbLog}, that has been extended with the neural predicates. In this way, the framework exploits the full expressiveness and strengths of general-purpose neural networks and expressive probabilistic-logical modeling and reasoning and can be trained end-to-end based on examples.

In this report, we focus on the application of DeepProbLog to the multi-digit MNIST octal-division task, a computer vision problem that involves dividing two multi-digit octal numbers. This task is challenging due to the large number of possible input-output pairs and the need to apply high-level reasoning to perform the division. Moreover the training set contains only single-digit numbers and the program is not explicitly trained on multi-digit numbers.

We begin by providing an overview of DeepProbLog and its key features in Section \ref{sec:DeepProbLog}. We then describe the multi-digit MNIST octal-division task in detail and explain how it can be formulated as a DeepProbLog program in Section \ref{sec:task}. Finally, in Section \ref{sec:results} we present experimental results that demonstrate the effectiveness of the DeepProbLog approach on this task.

% In this work, we introduce DeepProbLog explaining the basics of the language in Section \ref{sec:DeepProbLog}. Subsequently, in Section \ref{sec:task} we present the multi-digit MNIST octal-division task and how can be solved using DeepProbLog. Finally, in Section \ref{sec:results} we discuss the results obtained.

% TODO: finish introduction
Overall, our goal is to highlight the potential of DeepProbLog as a powerful tool for solving complex problems in artificial intelligence and machine learning, particularly those that require the integration of logical and probabilistic reasoning with statistical learning.